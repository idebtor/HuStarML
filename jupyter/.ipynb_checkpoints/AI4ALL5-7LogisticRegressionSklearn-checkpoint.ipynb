{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fear of the LORD is the beginning of knowledge, but fools despise wisdom and discipline. Proverbs 1:7\n",
    "\n",
    "-------\n",
    "\n",
    "# Welcome to \"AI for All\"\n",
    "\n",
    "Lecture Notes by idebtor@gmail.com, Handong Global University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Chapter 5-7 사이킷런의 로지스틱 회귀\n",
    "\n",
    "    5.1 퍼셉트론\n",
    "    5.2 시그모이드 함수\n",
    "    5.3 로지스틱 손실함수\n",
    "    5.4 이진 분류를 위한 데이터셋 준비\n",
    "    5.5 로지스틱 회귀 뉴론 만들기\n",
    "    5.6 로지스틱 회귀 뉴론으로 단일층 신경망 만들기\n",
    "    5.7 사이킷런의 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런에서 경사 하강법을 구현한 클래스 이름은 SGDClassifier입니다. 이 클래스는 로지스틱 회귀 문제 외에도 여러 가지 문제에 경사 하강법을 적용할 수 있습니다. 여기서는 SGDClassifier 클래스르 ㄹ통해 로지스틱 회귀 문제를 간단히 해결해 보겠습니다. (회귀 문제를 위해서는 SGDRegression를 사용합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 사이킷런으로 경사 하강법 적용하기 \n",
    "\n",
    "#### 1. 로지스틱 손실 함수 지정하기\n",
    "\n",
    "SGDClassifier클래스에 로지스틱 회귀를 적용하려면 loss매개변수에 손실 함수로 log를 지정합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(loss='log', max_iter=100, tol=1e-3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나머지 매개변수도 간단히 알아볼까요?  max_iter를 통해 반복 횟수를 100으로 지정하고 방복 실행했을 때 결과를 동일하게 재현하기 위해 random_state를 통해 난수 초깃값을 42로 설정합니다. 반복할 때마다 로지스틱 손실 함수의 값이 tol에 지정한 값만큼 감소되 않으면 반복을 중단하도록 설정합니다. 만약 tol값을 설정하지 않으면 max_iter의 값을 늘리라는 경고가 발생합니다. 이는 모델의 로지스틱 손실 함수의 값이 최적값으로 수렴할 정도로 충분한 횟수를 입력했는지 사용자에게 알려주므로 유용합니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 사이킷런으로 훈련하고 평가하기\n",
    "\n",
    "사이킷런의 SGDClassifier 클래스에는 지금까지 우리가 직접 구현한 메소드가 이미 준비되어 있습니다. 이름도 비슷하죠. 사이킷런의 fit() 메소드로 훈련하고 score()메소드로 정확도를 계산하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "x = cancer.data\n",
    "y = cancer.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.fit(x_train, y_train)\n",
    "sgd.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 사이킷런으로 예측하기 \n",
    "\n",
    "SGDClassifier클래스에도 예측을 위한 predict()메소드가 구현되어 있습니다. 실험삼아 테스트셋에 대한 예측을 만들어 볼 수 있습니다. 이 때 주의할 점은 사이킷런은 입력 데이터로 2차원 배열만 받아들입니다. 즉, 샘플 하나를 주입하더라도 2차원 배열로 만들어야 합니다. 여기서는 배열의 슬라이싱을 사용해 테스트셋에서 10개의 샘플만 뽑아 예측을 시도합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = sgd.predict(x_test)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 결과와 실제 타깃이 잘 들어맞는지 여러분이 직접 비교해 보세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고문헌\n",
    "\n",
    "1. 케라스 창시자에게 배우는 딥러닝, 프랑소와 숄레, 길벗\n",
    "1. 핸즈온 머신러닝, 오렐리앙 제롱, 한빛미디어\n",
    "1. 딥러닝 입문, 박해선, 이지스 퍼블리싱\n",
    "1. 파이썬으로 배우는 기계학습, 김영섭, K-MOOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "__Be joyful always!__ 1 Thes.5:16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
