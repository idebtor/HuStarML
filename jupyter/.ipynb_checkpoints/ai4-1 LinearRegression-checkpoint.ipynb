{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He has saved us and called us to a holy life — not because of anything we have done but because of his own purpose and grace. This grace was given us in Christ Jesus before the beginning of time. (2 Tim 1:9)  \n",
    "하나님이 우리를 구원하사 거룩하신 소명으로 부르심은 우리의 행위대로 하심이 아니요 오직 자기의 뜻과 영원 전부터 그리스도 예수 안에서 우리에게 주신 은혜대로 하심이라. (딤후1:9)\n",
    "\n",
    "-------\n",
    "\n",
    "# Welcome to \"AI for All\"\n",
    "\n",
    "Lecture Notes by idebtor@gmail.com, Handong Global University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Chapter 4. 선형 회귀(Linear Regression)\n",
    "\n",
    ":본 단원은 참고문헌 (3) & (4)에서 대부분  발췌한 것입니다. \n",
    "\n",
    "--------------\n",
    "\n",
    "가장 간단한 형태의 선형 회귀를 연습하면서도 기계학습과 딥러닝의 기초가 되며 핵심을 이해할 수 있는 시작입니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2장 정리하기 정답\n",
    "\n",
    "1. 입력\n",
    "1. 레이블(label) 혹은 타깃(target)\n",
    "1. 모델(model)\n",
    "1. 규칙 혹은 하이퍼파라미터(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 일차 함수로 이해하는 선형 회귀\n",
    "\n",
    "선형 회귀는 간단한 일차 함수로 표현할 수 있습니다. 선형 회귀의 선형이라는 단어의 의미는 다음 수식을 통해 그려지는 직선 그래프를 보면 쉽게 이해할 수 있습니다.  \n",
    "\n",
    "\\begin{equation}\n",
    "y = ax + b\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 일차 함수의 기울기(slope)는 $a$이고 절편(intercept)은 $b$입니다. 보통 이런 일차함수는 2차원 평면에 그리기 쉽습니다. \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/ai4all-graph1.png?raw=true\" width=\"400\">\n",
    "<center>그림 1: 일차 함수 그래프의 기울기와 절편 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 선형 회귀는 기울기와 절편을 찾아내는 것입니다.\n",
    "\n",
    "여기서, 선형 회귀는 기울기와 절편을 찾아내는 것입니다. 우리가 일차함수를 처음 배울 때를 생각해보면, 일차함수의 기울기와 절편이 주어지면 이를 만족하는 $x$와 $y$를 찾아내곤 했었죠? $x, y$ 좌표 평면에서 $(x, y)$좌표가 주어지면, 그 좌표가 직선 상에 있는지 없는지 알아보기도 했습니다. \n",
    "\n",
    "그런데, 선형 회귀에서는 이와 반대로, $x, y$가 주어졌을 때 기울기와 절편을 찾는데 우리의 관심이 있습니다. 즉, 선형 회귀의 주요 관심사는 '__절편과 기울기__를 찾는 것'입니다. 예를 들면, 선형 회귀로 다음과 같은 문제를 해결할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__선형 회귀 문제__: $(x, y) = (1, 4)$, $(x, y) = (2, 7)$, $(x, y )= (3, 10)$이라면 기울기와 절편의 값을 적절한 수식은 무엇인가요? \n",
    "\n",
    "(1) $y = 2x + 1 $ \n",
    "\n",
    "(2) $y = 3x + 2 $ \n",
    "\n",
    "(3) $y = 3x + 1 $ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잠시 생각해보면, 정답은 `_____`인 것을 어렵지 않게 찾아낼 수 있습니다. 그러면, 위 문제를 어떤 과정을 통해서 답을 계산해낼 수 있을까요? 다음을 보면서 조금 더 자세히 알아봅니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 그래프를 통해 선형 회귀의 문제 해결 과정을 이해합니다.\n",
    "\n",
    "앞에서 연습해 본 선형 회귀 문제를 그래프로 표현한 것입니다. 점은 x, y의 값을 나타낸 것이고, 직선은 보기(1)  $y = 2x + 1 $ 의 식을 그래프로 표현한 것입니다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/ai4all-graph2.png?raw=true\" width=\"300\">\n",
    "<center>그림 3: 일차 함수(y = 2x + 1)의 그래프 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빨간색의 점은 $(x, y)$의 값을 나타낸 것이고, 직선은 보기(1)의 직선을 표현한 것입니다. 보기(1)의 조건을 가진 식은 점들을 잘 표현하지 못하고 있습니다. 기울기도 절편의 위치도 상대적으로 좀 낮습니다. 그래서, 이제 __기울기와 절편의 값을 약간씩 높이도록 합니다.__ 기울기는 2에서 3으로, 절편은 1에서 2로 높여서, 다시 그래프를 그려 봅시다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/ai4all-graph3.png?raw=true\" width=\"300\">\n",
    "<center>그림 2: 일차 함수(y = 3x + 2)의 그래프 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 기울기는 비슷한 것 같은데, 직선의 위치가 전체적으로 위로 올라갔습니다. 그러므로, __이제는 절편만 좀 낮추면 될 것 같습니다.__ 절편을 2에서 1로 줄이고 다시 그래프를 그려봅니다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/ai4all-graph4.png?raw=true\" width=\"300\">\n",
    "<center>그림 4: 일차 함수(y = 3x + 1)의 그래프 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자~ 이번에는 직선이 각 점을 지나가고 있으므로, 일차 함수 직선이 점들을 잘 표현하고 있다고 말할 수 있습니다. 이러한 일차 함수들을 우리가 비록 손으로 혹은 암산으로 계산했지만, 이런 과정을 거치면서 만들어낸 __'선형 회귀로 만든 모델'__이라고 할 수 있습니다. \n",
    "\n",
    "이러한 모델이 정해지면, 이 __모델__을 통해서 새로운 점에 대한 __예측__을 할 수 있게 됩니다. 즉, 새로운 점의 'x 좌표가 5이면, y좌표는 아마도 16 정도일 것'이라는 예측을 할 수 있게 된 것입니다. \n",
    "\n",
    "> 미리 준비된 입력$(x: 1, 2, 3)$에 대한 레이블(타깃)$(y: 4, 7, 10)$을 가지고 모델$(y = 3x + 1)$을 만든 다음, 새 입력(5)에 대해 어떤 값(16)을 예측한 것입니다. 이것이 선형 회귀 모델을 만들어 문제를 해결하는 과정입니다.  \n",
    "\n",
    "참고로, 여기서 사용한 그래프를 그리는 파이썬 코드는 이 피일의 마지막 부분에 있으니, 참조하길 바랍니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습정리\n",
    "1. 선형 회귀는 기계학습 알고리즘 중 하나입니다. \n",
    "1. 선형 회귀는 2차원 평면에 놓은 점을 표현하는 일차함수의 기울기와 절편을 찾아냅니다.\n",
    "1. 선형 회귀로 찾은 이런 일차함수를 `_______`이라고 합니다. \n",
    "1. 선형 회귀 모델로 새 값 x에 대하여 y를 `_______`할 수 있습니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 당뇨병 환자의 데이터 다루기\n",
    "\n",
    "이제는 산업 현장에서 부딪히는 실제적이고 현실적인 문제에 도전해보겠습니다. 목표는 '당뇨병 환자의 1년 후 병의 진전된 정도를 예측하는 모델을 만드는 것'입니다. \n",
    "\n",
    "문제 해결을 위해 가장 먼저 해야 할 일은 충분한 양의 입력 데이터와 레이블(타깃) 데이터를 준비하는 것입니다. 지금부터 예제에서 사용할 입력 데이터와 레이블 데이터를 준비하겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷런에서 당뇨병 환자 데이터 가져오기\n",
    "\n",
    "딥러닝, 기계학습 패키지에는 인공지능 학습을 위한 데이터셋(dataset)이 준비되어 있는 경우가 많습니다. 이번에는 사이킷런의 데이터셋 중 당뇨병 황자의 데이터셋을 사용합니다. \n",
    "\n",
    "#### 1. load_diabetes()함수로 당뇨병 데이터 가져오기\n",
    "\n",
    "사이킷런의 datasets 모듈에 있는 load_diabetes()함수를 import한 후, 매개변수 값을 넣지 않은 채로 함수를 호출합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diabetes 변수에 저장된 값의 자료형은 파이썬 딕셔너리(dictionary)와 유사한 Bunch 클래스입니다. 이 클래스는 예제 데이터셋을 위해 준비된 것일 뿐 특별한 기능이 있는 건 아닙니다. 파이썬 딕셔너리라고 생각해도 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: Bunch 클래스와 사이킷런의 datasets 관련 정보는 [여기](https://www.kite.com/python/docs/sklearn.utils.Bunch) 를 참조하십시오. \n",
    "\n",
    "__Note__: scikit-learn의 대부분의 샘플 데이터는 Bunch 라는 클래스 객체로 생성됩니다. 이 클래스 객체는 다음과 같은 속성을 가집니다.\n",
    "\n",
    "- data: (필수) 독립 변수 ndarray 배열\n",
    "- target: (필수) 종속 변수 ndarray 배열\n",
    "- feature_names: (옵션) 독립 변수 이름 리스트\n",
    "- target_filename: (옵션) 종속 변수 이름 리스트\n",
    "- DESCR: (옵션) 자료에 대한 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
      "         0.01990842, -0.01764613],\n",
      "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
      "        -0.06832974, -0.09220405],\n",
      "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
      "         0.00286377, -0.02593034],\n",
      "       ...,\n",
      "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
      "        -0.04687948,  0.01549073],\n",
      "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
      "         0.04452837, -0.02593034],\n",
      "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
      "        -0.00421986,  0.00306441]]), 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
      "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
      "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
      "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
      "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
      "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
      "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
      "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
      "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
      "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
      "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
      "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
      "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
      "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
      "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
      "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
      "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
      "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
      "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
      "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
      "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
      "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
      "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
      "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
      "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
      "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
      "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
      "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
      "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
      "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
      "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
      "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
      "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
      "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
      "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
      "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
      "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
      "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
      "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
      "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
      "       220.,  57.]), 'frame': None, 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, T-Cells (a type of white blood cells)\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, thyroid stimulating hormone\\n      - s5      ltg, lamotrigine\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)', 'feature_names': ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], 'data_filename': 'C:\\\\Users\\\\user\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\diabetes_data.csv.gz', 'target_filename': 'C:\\\\Users\\\\user\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\diabetes_target.csv.gz'}\n"
     ]
    }
   ],
   "source": [
    "diabetes.feature_names\n",
    "print(diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 입력과 레이블(타깃) 데이터의 크기 확인하기\n",
    "\n",
    "diabetes의 속성 중 data 속성과 target 속성에는 우리에게 필요한 입력과 타깃(레이블) 데이터가 넘파이 배열로 저장되어 있습니다. 넘파이 배열의 크기는 shape 속성에 저장되어 있으며, 이를 출력해보는 것은 거의 필수적입니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1:\n",
    "입력 데이터와 타깃 데이터의 크기(shape, 형상)를 다음과 같은 것을 확인하십시오.  \n",
    "```\n",
    "(442, 10)\n",
    "(442,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(None)\n",
    "print(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diabetes.data는 442x10 크기의 2차원 배열이고, target은 442개의 요소를 가진 1차원 배열입니다. 다음 그림은 data와 target을 그림으로 나타낸 것입니다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/ai4all-diabetes1.png?raw=true\" width=\"600\">\n",
    "<center>그림 5: 당뇨병 환자의 데이터셋 구조 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋의 shape을 살펴보았듯이, diabetes.data를 보면, 442개의 행과 10개의 열로 구성되어 있습니다. 여기서 행은 샘플(sample, or example)이고, 열은 샘플의 __특성(feature)__입니다. 샘플이란 당뇨병 환자에 대한 특성으로 이루어진 데이터 한 셋을 의미하고, 특성은 당뇨병 데이터의 여러 특징들을 의미합니다. 쉽게 말해, 당뇨병 데이터에는 환자의 협압, 형당, 몸무게, 키 등의 특징(특성)이 있는데, 그 특징들의 수치를 모아 한 개의 샘플이 나오는 것입니다. 다음은 샘플과 특성의 이해를 돕기 위해 가상의 환자와 당노병 데이터를 그림으로 나타낸 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/ai4all-diabetes2.png?raw=true\" width=\"600\">\n",
    "<center>그림 6: 당뇨병 환자 샘플과 특성 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 입력 데이터의 특성은 다른 말로 속성, 독립 변수(independent variable), 설명 변수(explanatory variable)등으로 부릅니다. 이런 용어는 통계학에서 나온 것이 많은데, 여기서 기계학습에서 널리 통용되는 용어인 __특성(feature)__을 사용합니다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: \n",
    "\n",
    "당뇨병 환자 자료의 특성 이름들이 중요하거나 학습에 영향을 주는 것은 아니지만, 우리의 이해를 돕기위해 자료의 특성 이름들을 한 번 체크하는 것은 바람직한 일입니다. 자료의 특성들을 출력해 보십시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 입력 데이터 자세히 보기\n",
    "\n",
    "먼저 diabetes.data에 저장된 입력 데이터를 일부만 출력해 보겠습니다. \n",
    "\n",
    "\n",
    "#### Example:\n",
    "슬라이싱을 사용해 입력 데이터의 앞부분의 샘플 3개만 출력합니다. 이때 데이터셋의 첫 번째 샘플부터 추출한다면 첫 번째 인덱스는 생략해도 괜찮습니다.  출력된 자료의 형상(크기)는 무엇입니까? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "안쪽 대괄호에는 특성의 값 10개가 나열되어 있는데, 3개의 샘플을 추출했으므로, 3x10크기의 배열이 나타납니다. 당연하겠죠? \n",
    "\n",
    "#### 4. 타깃 데이터 자세히 보기 \n",
    "#### Example: \n",
    "이번에는 타깃 데이터도 첫 3개의 데이터를 출력하여 다음과 같은지 확인하십시오. \n",
    "```\n",
    "[151.,  75., 141.]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타깃 데이터는 10개의 요소로 구성된 샘플 1개에 대응됩니다. 예를 들면, 첫 번째 샘플 `[ 0.03807591,  0.05068012,  0.06169621,  0.02187235, -0.0442235, -0.03482076, -0.04340085, -0.00259226,  0.01990842, -0.01764613]`이라는 값은 151이라는 타깃 데이터에 대응됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 데이터를 놓고 잠시 생각해 봅시다. \n",
    "\n",
    "이 예제를 풀기 위해 입력 데이터와 타깃 데이터의 수치가 무엇을 의미하는지 반드시 알아야 할까요? \n",
    "\n",
    "그렇지 않습니다. 수치 자체에 대한 해석은 전문가(의사)의 영역입니다. 우리는 입력 데이터와 타깃 데이터의 수치만 보고 둘 사이의 규칙(모델)을 찾으면 됩니다. 하지만 실정에는 데이터의 의미를 아는 것이 매우 중요할 수 있으므로 이런 경우에는 해당 전문 분야 전문가의 도움을 받는 것이 좋습니다.(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 당뇨병 데이터 시각화하기\n",
    "\n",
    "데이터를 시각화가 가능하다면, 시각화 해보는 것은 기계학습의 필수적인 단계들 중에 하나입니다. 시각화 단계는 데이터의 유효성을 직감적으로 알 수 있는 좋은 수단입니다. 과연 당뇨병 데이터셋은 어떻게 생겼을까요? \n",
    "\n",
    "#### 1. 맷플롯립의 scatter()함수로 산점도 그리기\n",
    "당뇨병 데이터셋에는 10개의 특성이 있으므로 이 특성을 모두 그래프로 표형하려면 3차원 이상의 그래프를 그려야 합니다. 3차원 이상의 그래프는 그릴 수 없으므로 1개의 특성만 사용합니다. 여기서는 __세 번째 특성__과 __타깃 데이터__로 산점도를 그립니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(None, None, marker='^', color='green')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프의 x축은 diabetes.data의 세번째 특성이고, y축은 diabetes.target입니다.  이 그래프를 보면 세 번째 특성과 타깃 데이터 사이에 정비례 관계가 있음을 알 수 있습니다. 둘이 서로 관계가 있으며, 따라서 중요한 특성이라는 것을 알 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 훈련 데이터 준비하기\n",
    "\n",
    "매번 diabetes.data를 입력하여 입력 데이터의 속성을 참고하는 방법은 번거로우니, 입력 데이터의 __세 번째 특성__을 미리 분리하여 변수 x에 저장하고 타깃 데이터는 변수 y에 저장합니다. 이후 실습에서는 x에 있는 데이터와 y에 있는 데이터를 이용해 모델을 훈련할 것입니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None\n",
    "y = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 회귀 알고리즘 중 선형 회귀 알고리즘의 개념을 알아보고 실제 알고리즘을 만들어 보기 위한 당뇨병 데이터셋을 준비했습니다. 다음에는 이 데이터를 가지고 모델을 훈련하기 위한 핵심 최적화 알고리즘인 경사 하강법(gradient descent)에 대해 배웁니다. 그 다음에는 1개의 뉴론으로 구성된 첫 번째 모델을 만들 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "#### 타깃 데이터와 상관관계가 높은 특성을 찾아내기 \n",
    "\n",
    "우리는 앞에서 diabetes.data의 세번째 특성(bmi)과 diabetes.target를 산점도 그래프로 나타냈으며, 산점도 그래프를 통해서 두 데이터 사이에 정비례 관계가 있음을 알 수 있었습니다. diabetes.data에는 세번째 특성 외에 다른 특성들도 있는데, 이러한 특성들의 산점도를 그려보고, diabetes.target과 상관 관계가 가장 높은 하나의 특성을 찾아보십시오. \n",
    "\n",
    "Pyplot의 scatter() 함수를 사용하거나 혹은 Seaborn의 pairplot() 함수를 이용하는 방법도 있습니다. \n",
    "\n",
    "\n",
    "#### Answer(Feature Name): `_________________`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylot.scatter() 함수를 사용하기\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(None)\n",
    "plt.xlabel('feature x')\n",
    "plt.ylabel('target y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FYI: For your information\n",
    "\n",
    "### 1. Pandas DataFrame 자료 변환과 Seaborn을 이용한 산점도 그리기 \n",
    "\n",
    "Seaborn 라이브러리의 Pairplot()함수를 사용하여 여러 특성들의 상호 산점도를 그려서 전체적인 특성들의 상호 관계 정도를 좀 더 쉽게 파악할 수 있습니다. 다만, pairplot()은 pandas 자료 형식으로 입력 자료를 받기 때문에 sklearn 자료를 pandas자료 형식으로 먼저 변환하여야 합니다. 다음은 seaborn.pairplot() 함수의 매개변수들입니다. \n",
    "\n",
    "- `data`: tidy (long-form) dataframe where each column is a variable and each row is an observation.\n",
    "- `kind`: kind of plot to make {'scatter', 'kde', 'hist', 'reg'}\n",
    "- `hue`: variable in data to map plot aspects to different colors.\n",
    "- `markers`: single matplotlib marker code or list\n",
    "- `plot_kws`: for example, s for size, alpha for transparency: dict(scatter_kws=dict(s=3, alpha=0.5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 산점도는 diabetes.data의 처음 4 가지 특성들 중에서, 성별(sex)은 산점도의 색(orange and blue)으로 표시하고, 나머지 3개의 특성들이 산점도를 나타냅니다.  특히 가장 아래 행은 각 특성과 diabetes.target과의 상관 관계를 나타내고 있습니다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/ai4all-diabetes10.png?raw=true\" width=\"500\">\n",
    "<center>그림 1: 당뇨병 환자 특성들의 상호 상관관계 </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 자료 변환 \n",
    "df = pd.DataFrame(diabetes.data[:, :4], columns=diabetes.feature_names[:4])\n",
    "df['target'] = pd.Series(diabetes.target)\n",
    "\n",
    "# Seaborn 사용하여 상호 상관관계 그리기 \n",
    "sns.pairplot(None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. 선형 회귀 모델에 사용한 그래프를 그리는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "linex = np.array([x for x in range(-1, 5)])\n",
    "liney = 2 * linex + 1\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis('off')\n",
    "ax.axvline(0, linestyle='-', color='k') # vertical lines\n",
    "ax.axhline(0, linestyle='-', color='k') # horizontal line\n",
    "plt.title('y = 2x + 1')\n",
    "plt.axis([-1, 4, -1, 11])\n",
    "plt.plot(linex, liney, '-')\n",
    "plt.plot([1, 2, 3], [4, 7, 10], 'or' )\n",
    "plt.text(1, 4, '  (1, 4)')\n",
    "plt.text(2, 7, '  (2, 7)')\n",
    "plt.text(3, 10, '  (3, 10)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linex = np.array([x for x in range(-1, 5)])\n",
    "liney = 3 * linex + 2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis('off')\n",
    "ax.axvline(0, linestyle='-', color='k') # vertical lines\n",
    "ax.axhline(0, linestyle='-', color='k') # horizontal line\n",
    "plt.title('y = 3x + 2')\n",
    "plt.axis([-1, 4, -1, 11])\n",
    "plt.plot(linex, liney, '-')\n",
    "plt.plot([1, 2, 3], [4, 7, 10], 'or' )\n",
    "plt.text(1, 4, '  (1, 4)')\n",
    "plt.text(2, 7, '  (2, 7)')\n",
    "plt.text(3, 10, '  (3, 10)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linex = np.array([x for x in range(-1, 5)])\n",
    "liney = 3 * linex + 1\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis('off')\n",
    "ax.axvline(0, linestyle='-', color='k') # vertical lines\n",
    "ax.axhline(0, linestyle='-', color='k') # horizontal line\n",
    "plt.title('y = 3x + 1')\n",
    "plt.axis([-1, 4, -1, 11])\n",
    "plt.plot(linex, liney, '-')\n",
    "plt.plot([1, 2, 3], [4, 7, 10], 'or' )\n",
    "plt.text(1, 4, '  (1, 4)')\n",
    "plt.text(2, 7, '  (2, 7)')\n",
    "plt.text(3, 10, '  (3, 10)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고문헌\n",
    "\n",
    "1. 케라스 창시자에게 배우는 딥러닝, 프랑소와 숄레, 길벗\n",
    "1. 핸즈온 머신러닝, 오렐리앙 제롱, 한빛미디어\n",
    "1. 딥러닝 입문, 박해선, 이지스 퍼블리싱\n",
    "1. 파이썬으로 배우는 기계학습, 김영섭, K-MOOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "__Be joyful always!__ 1 Thes.5:16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
