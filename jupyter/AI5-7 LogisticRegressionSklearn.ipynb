{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예수께서 이르시되 내가 곧 길이요 진리요 생명이니 나로 말미암지 않고는 아버지께로 올 자가 없느니라 (요14:6)\n",
    "\n",
    "-------\n",
    "\n",
    "\n",
    "<center><img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/joyai/LectureNotes_ML.png?raw=true\" width=1000></center>\n",
    "\n",
    "__NOTE:__ The following materials have been compiled and adapted from the numerous sources including my own. Please help me to keep this tutorial up-to-date by reporting any issues or questions. Send any comments or criticisms to `idebtor@gmail.com` Your assistances and comments will be appreciated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"font-size:30px\"> Chapter 5-7 사이킷런의 로지스틱 회귀 </b> \n",
    "\n",
    "    5.1 퍼셉트론\n",
    "    5.2 시그모이드 함수\n",
    "    5.3 로지스틱 손실함수\n",
    "    5.4 이진 분류를 위한 데이터셋 준비\n",
    "    5.5 로지스틱 회귀 뉴론 만들기\n",
    "    5.6 로지스틱 회귀 뉴론으로 단일층 신경망 만들기\n",
    "    5.7 사이킷런의 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "사이킷런에서 경사 하강법을 구현한 클래스 이름은 `SGDClassifier`입니다. 이 클래스는 로지스틱 회귀 문제 외에도 여러 가지 문제에 경사 하강법을 적용할 수 있습니다. 여기서는 `SGDClassifier` 클래스를 통해 로지스틱 회귀 문제를 간단히 해결해 보겠습니다. (회귀 문제를 위해서는 `SGDRegression`를 사용합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사이킷런으로 경사 하강법 적용하기 \n",
    "\n",
    "## 로지스틱 손실 함수 지정하기\n",
    "사이킷런(scikit-learn)의 `SGDClassifier`클래스에 로지스틱 회귀를 적용하려면 `loss`매개변수에 손실 함수로 log를 지정합니다.\n",
    "- `sklearn`에서 `SGDClassifier`를 `import`하십시오. \n",
    "- SGDClasifier를 호출할 때 `loss = 'log'`이라고 설정하십시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(loss='log', max_iter=100, tol=1e-3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나머지 매개변수도 간단히 알아볼까요?  \n",
    "\n",
    "- `max_iter`를 통해 반복 횟수를 100으로 지정하고 방복 실행했을 때 결과를 동일하게 재현하기 위해 `random_stat`e를 통해 난수 초깃값을 42로 설정합니다.\n",
    "- 반복할 때마다 로지스틱 손실 함수의 값이 `tol`에 지정한 값만큼 감소되 않으면 반복을 중단하도록 설정합니다. 만약 `tol`값을 설정하지 않으면 `max_iter`의 값을 늘리라는 경고가 발생합니다. \n",
    "\n",
    "이는 모델의 로지스틱 손실 함수의 값이 최적값으로 수렴할 정도로 충분한 횟수를 입력했는지 사용자에게 알려주므로 유용합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사이킷런으로 훈련 자료를 준비하기\n",
    "이미 앞에서 연습한 유방암 자료를 가져오고, 훈련자료와 평가자료를 나누는 준비를 하십시오. \n",
    "각 훈련 자료와 테스트 자료의 형상(크기)를 확인하십시오. \n",
    "\n",
    "__Expected Output:__\n",
    "```\n",
    "x_train.shape:(455, 30)\n",
    "y_train.shape:(455,)\n",
    "x_test.shape:(114, 30)\n",
    "y_test.shape:(114,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "x = None\n",
    "y = None\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사이킷런으로 훈련하고 평가하기\n",
    "\n",
    "사이킷런의 `SGDClassifier` 클래스에는 지금까지 우리가 직접 구현한 메소드가 이미 준비되어 있습니다. 이름도 비슷하죠. \n",
    "\n",
    "- 사이킷런의 `fit()` 메소드로 훈련하고 \n",
    "- `score()`메소드로 정확도를 계산하면 됩니다. \n",
    "\n",
    "__Expected Output:__\n",
    "```\n",
    "0.8333333333333334\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사이킷런으로 훈련하고 평가하기\n",
    "\n",
    "사이킷런의 `SGDClassifier` 클래스에는 지금까지 우리가 직접 구현한 메소드가 이미 준비되어 있습니다. 이름도 비슷하죠. \n",
    "\n",
    "- 사이킷런의 `fit()` 메소드로 훈련하고 \n",
    "- `score()`메소드로 정확도를 계산하면 됩니다. \n",
    "\n",
    "__Expected Output:__\n",
    "```\n",
    "0.8333333333333334\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.fit(None)\n",
    "sgd.score(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = sgd.predict(x_test)\n",
    "print(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 결과와 실제 타깃이 잘 들어맞는지 여러분이 직접 비교해 보세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고문헌\n",
    "\n",
    "1. 케라스 창시자에게 배우는 딥러닝, 프랑소와 숄레, 길벗\n",
    "1. 핸즈온 머신러닝, 오렐리앙 제롱, 한빛미디어\n",
    "1. 딥러닝 입문, 박해선, 이지스 퍼블리싱\n",
    "1. 파이썬으로 배우는 기계학습, 김영섭, K-MOOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "__Be joyful always!__ 1 Thes.5:16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
